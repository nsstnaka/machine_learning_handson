{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NHyXeE41ayw",
        "colab_type": "text"
      },
      "source": [
        "# 機械学習ハンズオン（自然言語処理編1）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g04lvPI-1hH3",
        "colab_type": "text"
      },
      "source": [
        "## 1. ハンズオンの概要\n",
        "[IMDbのデータセット](https://ai.stanford.edu/~amaas/data/sentiment/)を使って、映画のレビュー文章から、そのレビューが肯定的か否定的かを判定する二値分類を行います。\n",
        "\n",
        "このハンズオンの流れは次の通りです。\n",
        "\n",
        " 1. データの取得\n",
        " 1. テキストの前処理\n",
        " 1. 学習モデルの作成・評価\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uev8Mwae2Inl",
        "colab_type": "text"
      },
      "source": [
        "## 2. 事前準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_EtxN-C2M8E",
        "colab_type": "text"
      },
      "source": [
        "### 2.1. ライブラリのロード\n",
        "必要なライブラリをimportします。Google Colabでは、これらのライブラリはすべてインストール済なので、改めてインストールする必要はありません。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4_VoYL_lMG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from gensim.models import word2vec\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M0Rg5usePWn",
        "colab_type": "text"
      },
      "source": [
        "### 2.2. NLTKの利用準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5F9cq1aibke",
        "colab_type": "text"
      },
      "source": [
        "後で利用するNLTKのAPIで必要なデータをあらかじめダウンロードしておきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clav7ovzeWUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO7kkXw02cBc",
        "colab_type": "text"
      },
      "source": [
        "## 3. データ取得"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcPUqh_0fVsC",
        "colab_type": "text"
      },
      "source": [
        "### 3.1. データのダウンロード・展開\n",
        "データ作成処理の簡略化のため、データ作成者が公開しているデータを使うのではなく、githubで公開されている別のデータファイルをダウンロードして使用することにします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_TBi-Mcf2n-",
        "colab_type": "text"
      },
      "source": [
        "ダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91sPwDQIGo1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/aaronkub/machine-learning-examples/raw/master/imdb-sentiment-analysis/movie_data.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYv8dTLSf47g",
        "colab_type": "text"
      },
      "source": [
        "ファイル展開"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu4NXSCUHtvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar zxvf movie_data.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtJmkeUMf69W",
        "colab_type": "text"
      },
      "source": [
        "### 3.2. データの読込\n",
        "pandasのAPIを使ってデータファイルを読みます。\n",
        "ヘッダーは自分で設定します。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhSif-viJucv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('./movie_data/full_train.txt', sep='\\t', names=['review'])\n",
        "train_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtBrcL3xhzQx",
        "colab_type": "text"
      },
      "source": [
        "レビューの文章を一つ見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2Ev370qOHbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['review'][7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVDDwPx6gD5v",
        "colab_type": "text"
      },
      "source": [
        "### 3.3. ラベル作成\n",
        "データファイルのうち、前半の12,500行が肯定的なレビュー、後半の12,500行が否定的なレビューです。\n",
        "\n",
        "肯定的なレビューには1、否定的なレビューには0のラベルを付与します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsAsKUicMK16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ys = np.array([1 if i < 12500 else 0 for i in range(25000)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TWTw0p6iFM7",
        "colab_type": "text"
      },
      "source": [
        "## 4. テキストの前処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqYM4f9RjZpS",
        "colab_type": "text"
      },
      "source": [
        "### 4.1. テキストのクリーニング\n",
        "ここでは次の処理を行います。\n",
        " * 不要な要素の除去\n",
        "   * HTMLタグ（BeautifulSoupというライブラリを使います）\n",
        "   * 角かっこ(`[ ]`)で囲まれた部分\n",
        "   * 英字以外の文字\n",
        " * 小文字化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIs1Tprftlia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "  text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "  text = re.sub('\\[[^]]*\\]', ' ', text)\n",
        "  text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "  text = text.lower()\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO3mTP3EuEAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['review'] = train_df['review'].apply(clean_text)\n",
        "train_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gQDYJRmj68C",
        "colab_type": "text"
      },
      "source": [
        "サンプルをみてみましょう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW0502NquVE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['review'][7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql6pIW8bj-YJ",
        "colab_type": "text"
      },
      "source": [
        "### 4.2. ストップワードの除去\n",
        "頻繁に登場しすぎて特徴にするには不適切な単語を除去します。\n",
        "\n",
        "除去の候補となる単語は、NLTKに登録済みのものとします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfWZoXvj1C1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_stopwords = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gQJO2lWzblD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stopwords(text):\n",
        "  return ' '.join([word for word in text.split() if word not in english_stopwords])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5u5x3dTUtf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['review'] = train_df['review'].apply(remove_stopwords)\n",
        "train_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJjCWljS3SSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['review'][7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYSuOhNXkaMx",
        "colab_type": "text"
      },
      "source": [
        "### 4.3. レンマ化\n",
        "単語を原型に変換します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6PBzJY3V6wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "def lemmatize(text):\n",
        "  return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1Tcz_mo3Z2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['review'] = train_df['review'].apply(lemmatize)\n",
        "train_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "osZ3KreO3fFB",
        "colab": {}
      },
      "source": [
        "train_df['review'][7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6978Y5nknCd",
        "colab_type": "text"
      },
      "source": [
        "## 5. 特徴量の生成 → 学習 →評価\n",
        "前処理したテキストから各テキストの特徴量を生成し、それを学習させ、精度を評価しましょう。\n",
        "\n",
        "ここでは次の手法の評価をします。\n",
        " * 単語カウント\n",
        " * TF-IDF\n",
        " * word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2Fuahfg3qem",
        "colab_type": "text"
      },
      "source": [
        "### 5.1. 単語カウント\n",
        "scikit-learnの`CountVectorizer`を使って特徴量を生成します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpUfoIQ933F2",
        "colab_type": "text"
      },
      "source": [
        "特徴量生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0Z-vfRD4U4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = CountVectorizer()\n",
        "Xs = cv.fit_transform(train_df['review'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uYqYgeE3yfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPvSNziE35He",
        "colab_type": "text"
      },
      "source": [
        "訓練データと検証データに分割"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qphbun9t43xH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "  Xs, Ys, train_size = 0.8\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHfl08Df3-AB",
        "colab_type": "text"
      },
      "source": [
        "学習・評価\n",
        "（学習率を変えて6パターンで実験）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smC-HVja5Uvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rates = [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]\n",
        "for lr in learning_rates:\n",
        "  model = LogisticRegression(C=lr, max_iter=1000)\n",
        "  model.fit(X_train, y_train)\n",
        "  print (\"Accuracy for C=%s: %s\" % (lr, accuracy_score(y_val, model.predict(X_val))))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2JJAyinvpJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(model.coef_[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqI2ZhjxwLx2",
        "colab_type": "text"
      },
      "source": [
        "係数の大きい／小さい単語を確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HXhI97jqKKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = cv.get_feature_names()\n",
        "coefs = {word: coef for word, coef in zip(words, model.coef_[0])}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B4qA7cbs6cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for best_positive in sorted(coefs.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
        "    print (best_positive)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcSkKNvztlzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for best_negative in sorted(coefs.items(), key=lambda x: x[1], reverse=False)[:5]:\n",
        "    print (best_negative)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fbk_0vt4LCV",
        "colab_type": "text"
      },
      "source": [
        "### 5.2. TF-IDF\n",
        "scikit-learnの`TfidfVectorizer`を使って特徴量を生成します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5Furhu64T4t",
        "colab_type": "text"
      },
      "source": [
        "特徴量生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlOgWKS75iIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "Xs = tfidf.fit_transform(train_df['review'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUkQVvup4V8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltQnUWH84XFb",
        "colab_type": "text"
      },
      "source": [
        "訓練データと検証データに分割"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i_ARXj3596c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "  Xs, Ys, train_size = 0.8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4PKZB314iHo",
        "colab_type": "text"
      },
      "source": [
        "学習・評価 （学習率を変えて6パターンで実験）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiniRGMS6BB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rates = [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]\n",
        "for lr in learning_rates:\n",
        "  model = LogisticRegression(C=lr, max_iter=1000)\n",
        "  model.fit(X_train, y_train)\n",
        "  print (\"Accuracy for C=%s: %s\" % (lr, accuracy_score(y_val, model.predict(X_val))))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SRHi7ugyB7t",
        "colab_type": "text"
      },
      "source": [
        "係数の大きい／小さい単語を確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lpmtE7fIwz63",
        "colab": {}
      },
      "source": [
        "words = cv.get_feature_names()\n",
        "coefs = {word: coef for word, coef in zip(words, model.coef_[0])}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r1bKk8lZxF1D",
        "colab": {}
      },
      "source": [
        "for best_positive in sorted(coefs.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
        "    print (best_positive)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8u3QhohuxSK6",
        "colab": {}
      },
      "source": [
        "for best_negative in sorted(coefs.items(), key=lambda x: x[1], reverse=False)[:5]:\n",
        "    print (best_negative)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kkjfc-sCyjde",
        "colab_type": "text"
      },
      "source": [
        "### 5.3. word2vec\n",
        "word2vecを使って単語のベクトルを生成します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-eBVIh3yypt",
        "colab_type": "text"
      },
      "source": [
        "単語ベクトル生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaE9HalNbmWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = [text.split() for text in train_df['review'].values]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6PnvWmcaAK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v = word2vec.Word2Vec(sentences,\n",
        "                        size=100,\n",
        "                        window=5,\n",
        "                        min_count=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q5MF-TXy2zc",
        "colab_type": "text"
      },
      "source": [
        "単語ベクトルからテキストの特徴量作成\n",
        "（出現する単語のベクトルの平均をテキストの特徴量とする）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ2EL1vlc7pH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xs = np.array([list(np.mean(w2v[[word for word in sentence if word in w2v]], axis=0)) for sentence in sentences])\n",
        "Xs.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bzCfWj5zEn3",
        "colab_type": "text"
      },
      "source": [
        "訓練データと検証データに分割"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0JJ_7yzpLry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "  Xs, Ys, train_size = 0.8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOOQjnVzKMm",
        "colab_type": "text"
      },
      "source": [
        "学習・評価 （学習率を変えて6パターンで実験）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPbizbpXpQ6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rates = [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]\n",
        "for lr in learning_rates:\n",
        "  model = LogisticRegression(C=lr, max_iter=1000)\n",
        "  model.fit(X_train, y_train)\n",
        "  print (\"Accuracy for C=%s: %s\" % (lr, accuracy_score(y_val, model.predict(X_val))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JmZdP0JzdiR",
        "colab_type": "text"
      },
      "source": [
        "単語のベクトルを可視化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsKte2fq7WBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "limit = 1000  # プロットする単語数"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRscRTCu3oHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = []\n",
        "for word in w2v.wv.vocab:\n",
        "  embeddings.append(w2v[word])\n",
        "    \n",
        "tsne = TSNE(n_components=2)\n",
        "new_values = tsne.fit_transform(embeddings[:limit])\n",
        "\n",
        "Xs = [coords[0] for coords in new_values]\n",
        "Ys = [coords[1] for coords in new_values]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJf0CYrZ4WgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = list(w2v.wv.vocab)[:limit]\n",
        "plt.figure(figsize=(20, 20)) \n",
        "for i in range(limit):\n",
        "  plt.scatter(Xs[i],Ys[i])\n",
        "  plt.annotate(labels[i], xy=(Xs[i], Ys[i]), xytext=(5, 2),\n",
        "                 textcoords='offset points', ha='right', va='bottom')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfhqklDv6m5t",
        "colab_type": "text"
      },
      "source": [
        "## 6. チャレンジ課題\n",
        " * SVMやランダムフォレストなどの他の分類器を使ってモデルを作ってみましょう。\n",
        " * 作ったモデルの混同行列(confusion matrix)を見てみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwtjevM38UMU",
        "colab_type": "text"
      },
      "source": [
        "## 7. 参考\n",
        " * [Approaches of NLP and Sentiment Classification](https://www.kaggle.com/subhamoybhaduri/approaches-of-nlp-and-sentiment-classification)\n",
        " * [Sentiment Analysis with Python (Part 1)](https://towardsdatascience.com/sentiment-analysis-with-python-part-1-5ce197074184)\n",
        " * [Sentiment Analysis with Python (Part 2)](https://towardsdatascience.com/sentiment-analysis-with-python-part-2-4f71e7bde59a)"
      ]
    }
  ]
}