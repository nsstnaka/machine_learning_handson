{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "knowledge_graph_embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nsstnaka/machine_learning_handson/blob/master/knowledge_graph_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPu8SZlWNh3q"
      },
      "source": [
        "# 機械学習ハンズオン（ナレッジグラフ埋め込み）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5p4UE4tNmf3"
      },
      "source": [
        "## 1. ハンズオンの概要\n",
        "TransEでナレッジグラフの埋め込み表現を学習し、未知の質問に対して推論を試します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjjTUzkWRKyx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C20UxqVZOJgD"
      },
      "source": [
        "## 2. データ取得"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p49jkxYOdGe"
      },
      "source": [
        "### 2.1. データのダウンロード・展開\n",
        "データは\"Cross-lingual entity alignment via joint attribute-preserving embedding\"の論文の実験で使用したものを使います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8El-LUsQpgU"
      },
      "source": [
        "!wget -nc https://github.com/nju-websoft/JAPE/raw/master/data/dbp15k.tar.gz\n",
        "!tar zxf dbp15k.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og3OkF2KU8BO"
      },
      "source": [
        "### 2.2. ファイル読込"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLNPINcrSSLE"
      },
      "source": [
        "df = pd.read_csv('dbp15k/ja_en/s_triples', sep='\\t', names=['head', 'relation', 'tail'])\n",
        "print(len(df))\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASi59sRfVDWp"
      },
      "source": [
        "## 3. 前処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI9s02ncVILF"
      },
      "source": [
        "### 3.1. 各エンティティ・リレーションの`http://...`を除去"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_NY2KvwUHLt"
      },
      "source": [
        "df = df.applymap(lambda x: x.split('/')[-1])\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bTEvYjHVUTJ"
      },
      "source": [
        "### 3.2. 名称→通し番号への変換\n",
        "エンティティおよびリレーションの名称を番号に変換します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZIGb9VKWdIO"
      },
      "source": [
        "entity_set = set(df['head']) | set(df['tail'])\n",
        "relation_set = set(df['relation'])\n",
        "len(entity_set), len(relation_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibB8xm4VXZ5M"
      },
      "source": [
        "entity_idx_dic = {name: idx for idx, name in enumerate(entity_set)}\n",
        "entity_name_dic = {idx: name for name, idx in entity_idx_dic.items()}\n",
        "relation_idx_dic = {name: idx for idx, name in enumerate(relation_set)}\n",
        "relation_name_dic = {idx: name for name, idx in relation_idx_dic.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXEQGnMIIEq8"
      },
      "source": [
        "df['head_idx'] = df['head'].apply(lambda x: entity_idx_dic[x])\n",
        "df['relation_idx'] = df['relation'].apply(lambda x: relation_idx_dic[x])\n",
        "df['tail_idx'] = df['tail'].apply(lambda x: entity_idx_dic[x])\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBH0mi2wVsS4"
      },
      "source": [
        "### 3.3. テスト用のトリプルの選定\n",
        "推論のテストに使用するトリプルを1つ選び、訓練データから除去します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YhtO2wsExiY"
      },
      "source": [
        "df[(df['head'] == 'イギリス') & (df['relation'] == '首都')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eazGP78GgGO"
      },
      "source": [
        "test_head = entity_idx_dic['イギリス']\n",
        "test_relation = relation_idx_dic['首都']\n",
        "test_tail = entity_idx_dic['ロンドン']\n",
        "test_head, test_relation, test_tail"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTJJ9aUdG0IF"
      },
      "source": [
        "df.drop(4917, axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LynD-wxuV-ve"
      },
      "source": [
        "## 4. 学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQg26xHYWAw5"
      },
      "source": [
        "### 4.1. 各種設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7A0BO4cLqQa"
      },
      "source": [
        "EMBEDDING_DIM = 75  # 埋め込みの次元数\n",
        "TRAIN_BATCH_SIZE = 256  # 学習バッチサイズ\n",
        "SCORE_FUNC = 'L1'  # 距離の計算方法 'L1'（マンハッタン距離） or 'L2'（ユークリッド距離）\n",
        "NORMALIZE = True  # ベクトルのL2正規化有無\n",
        "EPOCHS = 50  # 学習エポック数"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YR_rPisWWpJ"
      },
      "source": [
        "### 4.2. 余計な列の除去\n",
        "訓練に使わない列は除去しておきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LxIpjXyKeEN"
      },
      "source": [
        "df.drop(['head', 'relation', 'tail'], axis=1, inplace=True)\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCwMcomvWbDd"
      },
      "source": [
        "### 4.3. 訓練データの生成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypq3kJE1Wfyq"
      },
      "source": [
        "負例を作る際にヘッドを入れ替えるかテイルを入れ替えるかの確率を生成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7jPZ33eIs15"
      },
      "source": [
        "head_count = df.groupby('relation_idx')['head_idx'].apply(set).apply(len)\n",
        "tail_count = df.groupby('relation_idx')['tail_idx'].apply(set).apply(len)\n",
        "tail_prob = tail_count / (head_count + tail_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGFL7MRYWrVI"
      },
      "source": [
        "訓練データのgeneratorの定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLAQxc0p9gIL"
      },
      "source": [
        "def data_generator(num_entities, triples, prob):\n",
        "    triple_set = {(row[0], row[1], row[2]) for row in triples}\n",
        "    for head, relation, tail in np.random.permutation(triples):\n",
        "        neg_head = None\n",
        "        neg_tail = None\n",
        "        if random.random() > prob[relation]:\n",
        "            # replace head\n",
        "            neg_tail = tail\n",
        "            while True:\n",
        "                neg_head = random.randrange(num_entities)\n",
        "                if (neg_head, relation, tail) not in triple_set:\n",
        "                    break\n",
        "        else:\n",
        "            # replace tail\n",
        "            neg_head = head\n",
        "            while True:\n",
        "                neg_tail = random.randrange(num_entities)\n",
        "                if (head, relation, neg_tail) not in triple_set:\n",
        "                    break\n",
        "        yield [head, relation, tail, neg_head, neg_tail]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb888HssWvHI"
      },
      "source": [
        "generatorから`tf.data`のDatasetを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bThmV3RALM45"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_generator(data_generator, args=[len(entity_idx_dic), df.values, tail_prob], output_types=(tf.int64), output_shapes=(5,)).shuffle(10000).batch(TRAIN_BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1vgWO_cW1M1"
      },
      "source": [
        "### 4.4. 学習モデル構築"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF_flMUSW5gb"
      },
      "source": [
        "距離の算出関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jru8Ld79M9ij"
      },
      "source": [
        "def score_func(heads, tails, relations):\n",
        "    #return tf.square(tf.norm(heads + relations - tails, ord=2, axis=-1))\n",
        "    if SCORE_FUNC == 'L1':\n",
        "        return tf.norm(heads + relations - tails, ord=1, axis=-1)\n",
        "    elif SCORE_FUNC == 'L2':\n",
        "        return tf.square(tf.norm(heads + relations - tails, ord=2, axis=-1))\n",
        "    else:\n",
        "        raise Exception('Invalid SCORE_FUNC:', SCORE_FUNC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcsCNHSIW9D7"
      },
      "source": [
        "埋め込みの定義と初期化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoQmvoZ_PYxZ"
      },
      "source": [
        "bound = 6 / math.sqrt(EMBEDDING_DIM)\n",
        "initializer = tf.keras.initializers.RandomUniform(minval=-bound, maxval=bound)\n",
        "entity_embeddings = tf.keras.layers.Embedding(len(entity_idx_dic), EMBEDDING_DIM,\n",
        "                                              embeddings_initializer=initializer)\n",
        "relation_embeddings = tf.keras.layers.Embedding(len(entity_idx_dic), EMBEDDING_DIM,\n",
        "                                                embeddings_initializer=initializer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xiv-PaOXAB1"
      },
      "source": [
        "学習部分の定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f33qHK_dPezE"
      },
      "source": [
        "margin = 1.0\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "#optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "@tf.function\n",
        "def train_step(inputs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        heads = entity_embeddings(inputs[:, 0])\n",
        "        relations = relation_embeddings(inputs[:, 1])\n",
        "        tails = entity_embeddings(inputs[:, 2])\n",
        "        neg_heads = entity_embeddings(inputs[:, 3])\n",
        "        neg_tails = entity_embeddings(inputs[:, 4])\n",
        "        if NORMALIZE:\n",
        "            heads = tf.nn.l2_normalize(heads, axis=-1)\n",
        "            tails = tf.nn.l2_normalize(tails, axis=-1)\n",
        "            relations = tf.nn.l2_normalize(relations, axis=-1)\n",
        "            neg_heads = tf.nn.l2_normalize(neg_heads, axis=-1)\n",
        "            neg_tails = tf.nn.l2_normalize(neg_tails, axis=-1)\n",
        "        pos_scores = score_func(heads, tails, relations)\n",
        "        neg_scores = score_func(neg_heads, neg_tails, relations)\n",
        "        loss = tf.reduce_sum(tf.maximum(pos_scores + margin - neg_scores, 0.0))\n",
        "    #print(variables)\n",
        "    variables = entity_embeddings.trainable_variables + relation_embeddings.trainable_variables\n",
        "    grads = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(grads, variables))\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkkN3tgXXEMU"
      },
      "source": [
        "学習実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gp_4iEjPqbT"
      },
      "source": [
        "for e in range(1, EPOCHS+1):\n",
        "    total_loss = 0.0\n",
        "    for batch_data in train_ds:\n",
        "        loss = train_step(batch_data)\n",
        "        total_loss += loss.numpy()\n",
        "    print(\"Epoch {}: loss={:.6f}\".format(e, total_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1TSJ7UtXRsc"
      },
      "source": [
        "## 5. 推論実行"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5gLbtn5XXsn"
      },
      "source": [
        "学習済みの埋め込みから、テスト用のヘッドとリレーションに該当する埋め込みを取得します。\n",
        "（後で計算が楽になるように、事前にこれらを足しておきます）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoFaD3OrTt7R"
      },
      "source": [
        "test_entity_emb = entity_embeddings(test_head)\n",
        "test_relation_emb = entity_embeddings(test_relation)\n",
        "if NORMALIZE:\n",
        "  test_entity_emb = tf.nn.l2_normalize(test_entity_emb)\n",
        "  test_relation_emb = tf.nn.l2_normalize(test_relation_emb)\n",
        "target_emb = tf.expand_dims(tf.nn.l2_normalize(entity_embeddings(test_head)) + relation_embeddings(test_relation), axis=0)\n",
        "target_emb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hin_GQpwXlTC"
      },
      "source": [
        "推論結果の候補となるエンティティ（つまりすべてのエンティティ）の埋め込み表現を取得します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdy60EFcPUso"
      },
      "source": [
        "all_entity_embs = entity_embeddings(np.array(range(len(entity_idx_dic))))\n",
        "if NORMALIZE:\n",
        "  all_entity_embs = tf.nn.l2_normalize(all_entity_embs, axis=-1)\n",
        "all_entity_embs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5rBrgJjXs6L"
      },
      "source": [
        "$head + relation - tail$の距離を算出（この距離が最も近いものが最有力候補となる）し、距離が近い順に候補のエンティティを並べ替えます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-WMXn5fQ7h4"
      },
      "source": [
        "if SCORE_FUNC == 'L1':\n",
        "  nearest_entities = tf.argsort(tf.linalg.norm(target_emb - all_entity_embs, ord=1, axis=-1)).numpy()\n",
        "else:  # L2\n",
        "  nearest_entities = tf.argsort(tf.linalg.norm(target_emb - all_entity_embs, ord=2, axis=-1)).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcCDb_BPYACp"
      },
      "source": [
        "正解のテイルが何番目に入っているかを確認します（この順位が小さいほうが精度が良いことになります）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v65xBNtsSEqq"
      },
      "source": [
        "rank = 0\n",
        "for i in range(len(entity_idx_dic)):\n",
        "  if nearest_entities[i] == test_tail:\n",
        "    rank = i+1\n",
        "    break\n",
        "print(rank)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}